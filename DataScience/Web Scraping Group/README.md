# ğŸ•·ï¸ Web Scraping Group Project

<div align="center">

![Tech](https://img.shields.io/badge/Tech-BeautifulSoup_%7C_Selenium-success?style=for-the-badge)
![Domain](https://img.shields.io/badge/Domain-Data_Engineering-blue?style=for-the-badge)

**"Extracting Real-world Data from Websites"**

</div>

---

## ğŸ¯ Problem Statement
à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸¡à¸µà¸„à¹ˆà¸²à¸ªà¹ˆà¸§à¸™à¹ƒà¸«à¸à¹ˆà¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¸£à¸¹à¸›à¹à¸šà¸š API à¹à¸•à¹ˆà¸­à¸¢à¸¹à¹ˆà¸šà¸™à¸«à¸™à¹‰à¸²à¹€à¸§à¹‡à¸šà¹„à¸‹à¸•à¹Œ à¹‚à¸ˆà¸—à¸¢à¹Œà¸„à¸·à¸­à¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡ **Scraper** à¹€à¸à¸·à¹ˆà¸­à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸´à¸™à¸„à¹‰à¸²/à¸£à¸²à¸„à¸² à¸¡à¸²à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸•à¹ˆà¸­

## ğŸ—ï¸ Scraping Pipeline

```mermaid
sequenceDiagram
    participant Scraper
    participant Target as Target Website
    participant Parser
    participant CSV

    Scraper->>Target: HTTP Request (GET)
    Target-->>Scraper: HTML Response
    Scraper->>Parser: Parse HTML (BeautifulSoup)
    Parser->>Parser: Find Elements (div.product)
    Parser-->>CSV: Write Data (Name, Price)
```

## ğŸ’» Tech Stack
- **Requests**: à¸ªà¸³à¸«à¸£à¸±à¸šà¸¢à¸´à¸‡ HTTP GET
- **BeautifulSoup4**: à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸›à¸¥à¸‡ HTML à¹€à¸›à¹‡à¸™ Object à¸—à¸µà¹ˆà¸„à¹‰à¸™à¸«à¸²à¹„à¸”à¹‰
- **Pandas**: à¸ªà¸³à¸«à¸£à¸±à¸šà¸ˆà¸±à¸”à¸£à¸¹à¸›à¹à¸šà¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¹ˆà¸­à¸™ Save à¹€à¸›à¹‡à¸™ CSV

```python
soup = BeautifulSoup(response.content, 'html.parser')
prices = soup.find_all('span', class_='price')
```

## ğŸ’¡ Key Learnings
- **HTML DOM**: à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡ Tree à¸‚à¸­à¸‡à¸«à¸™à¹‰à¸²à¹€à¸§à¹‡à¸š
- **Ethics**: à¸¡à¸²à¸£à¸¢à¸²à¸—à¹ƒà¸™à¸à¸²à¸£ Scraping (à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š `robots.txt` à¹à¸¥à¸°à¹„à¸¡à¹ˆà¸¢à¸´à¸‡ Request à¸–à¸µà¹ˆà¹€à¸à¸´à¸™à¹„à¸›)
